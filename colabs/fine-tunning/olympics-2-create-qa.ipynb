{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange; font-weight:bold\">Note: To answer questions based on text documents, we recommend the procedure in <a href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\">Question Answering using Embeddings</a>. Some of the code below may rely on <a href=\"https://github.com/openai/openai-cookbook/tree/main/transition_guides_for_deprecated_API_endpoints\">deprecated API endpoints</a>.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating a synthetic Q&A dataset\n",
    "We use [`davinci-instruct-beta-v3`](https://beta.openai.com/docs/engines/instruct-series-beta), a model specialized in following instructions, to create questions based on the given context. Then we also use [`davinci-instruct-beta-v3`](https://beta.openai.com/docs/engines/instruct-series-beta) to answer those questions, given the same context. \n",
    "\n",
    "This is expensive, and will also take a long time, as we call the davinci engine for each section. You can simply download the final dataset instead.\n",
    "\n",
    "We're using the dataset created using the [previous notebook](olympics-1-collect-data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Read in the data, and create a context\n",
    "Create a context by concatenating the title, the heading and the content of that section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'olympics-data/olympics_sections.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rulz-ai/Rulz-AI/colabs/fine-tunning/olympics-2-create-qa.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rulz-ai/Rulz-AI/colabs/fine-tunning/olympics-2-create-qa.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rulz-ai/Rulz-AI/colabs/fine-tunning/olympics-2-create-qa.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39molympics-data/olympics_sections.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rulz-ai/Rulz-AI/colabs/fine-tunning/olympics-2-create-qa.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mtitle \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m df\u001b[39m.\u001b[39mheading \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m df\u001b[39m.\u001b[39mcontent\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rulz-ai/Rulz-AI/colabs/fine-tunning/olympics-2-create-qa.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'olympics-data/olympics_sections.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"olympics-data/olympics_sections.csv\")\n",
    "df[\"context\"] = df.title + \"\\n\" + df.heading + \"\\n\\n\" + df.content\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create questions based on the context\n",
    "Use davinci-instruct to generate a number of plausible questions relating to the Wikipedia section contents.\n",
    "\n",
    "Note: We have used temperature=0, but it may be beneficial to experiment with a higher temperature to get a higher diversity of questions.\n",
    "\n",
    "<span style=\"color:orange; font-weight:bold\">WARNING: This step will last a long time, and consume a lot of tokens, as it calls davinci-instruct for every section to generate a number of questions.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39mapply(get_questions)\n\u001b[0;32m     22\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m df\u001b[39m.\u001b[39mquestions\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(df[[\u001b[39m\"\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "def get_questions(context):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci-instruct-beta-v3\",\n",
    "            prompt=f\"Write questions based on the text below\\n\\nText: {context}\\n\\nQuestions:\\n1.\",\n",
    "            temperature=0,\n",
    "            max_tokens=257,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=[\"\\n\\n\"],\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"]\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "df[\"questions\"] = df.context.apply(get_questions)\n",
    "df[\"questions\"] = \"1.\" + df.questions\n",
    "print(df[[\"questions\"]].values[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt is designed to generate a number of questions. Example questions above were generated based on the summary section of the 2020 Summer Olympics page.\n",
    "\n",
    "We can observe that the questions 3 and 5 above repeat. Sometimes the generated questions could be ambiguous without the context. We will show that even despite these limitations we can create a successful model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.content.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create answers based on the context\n",
    "Use davinci-instruct to answer the questions given the relevant Wikipedia section contents\n",
    "\n",
    "Note: We have used temperature=0, but it may be beneficial to experiment with a higher temperature to get a higher diversity of questions.\n",
    "\n",
    "<span style=\"color:orange\">**WARNING: This step will last a long time, and consume a lot of tokens, as it calls davinci-instruct for every section to answer all the questions.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[39mprint\u001b[39m(e)\n\u001b[0;32m     15\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(get_answers, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m df\u001b[39m.\u001b[39manswers\n\u001b[0;32m     20\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def get_answers(row):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci-instruct-beta-v3\",\n",
    "            prompt=f\"Write answer based on the text below\\n\\nText: {row.context}\\n\\nQuestions:\\n{row.questions}\\n\\nAnswers:\\n1.\",\n",
    "            temperature=0,\n",
    "            max_tokens=257,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "df[\"answers\"] = df.apply(get_answers, axis=1)\n",
    "df[\"answers\"] = \"1.\" + df.answers\n",
    "df = df.dropna().reset_index().drop(\"index\", axis=1)\n",
    "print(df[[\"answers\"]].values[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the answers to the questions above based on the context around the host city selection. \n",
    "\n",
    "We can see that answers 3-5 contain the correct answer, but instead of answering the question directly, the answer is a verbatim extraction. Despite these occasional lower quality answers, we will show that the model can learn the task reasonably well, given a high number of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Save the Olympics Q&A dataset based on Wikipedia sections\n",
    "We save the file for use in the [next notebook](olympics-3-train-qa.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39molympics-data/olympics_qa.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"olympics-data/olympics_qa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Search file (DEPRECATED)\n",
    "We create a search file ([API reference](https://beta.openai.com/docs/api-reference/files/list)), which can be used to retrieve the relevant context when a question is asked.\n",
    "\n",
    "<span style=\"color:orange; font-weight:bold\">DEPRECATED: The /search endpoint is deprecated in favour of using embeddings. Embeddings are cheaper, faster and can support a better search experience. See <a href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\">Question Answering Guide</a> for a search implementation using the embeddings</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mtokens \u001b[39m<\u001b[39m \u001b[39m2000\u001b[39m]\n\u001b[0;32m      2\u001b[0m df[[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mrename(\n\u001b[0;32m      3\u001b[0m     columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m      4\u001b[0m )\u001b[39m.\u001b[39mto_json(\u001b[39m\"\u001b[39m\u001b[39molympics-data/olympics_search.jsonl\u001b[39m\u001b[39m\"\u001b[39m, orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m\"\u001b[39m, lines\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m search_file \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mFile\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m      7\u001b[0m     file\u001b[39m=\u001b[39m\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39molympics-data/olympics_search.jsonl\u001b[39m\u001b[39m\"\u001b[39m), purpose\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df[df.tokens < 2000]\n",
    "df[[\"context\", \"tokens\"]].rename(\n",
    "    columns={\"context\": \"text\", \"tokens\": \"metadata\"}\n",
    ").to_json(\"olympics-data/olympics_search.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "search_file = openai.File.create(\n",
    "    file=open(\"olympics-data/olympics_search.jsonl\"), purpose=\"search\"\n",
    ")\n",
    "olympics_search_fileid = search_file[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Answer questions based on the context provided\n",
    "\n",
    "We will use a simple implementation of the answers endpoint. This works by simply using the [/search endpoint](https://beta.openai.com/docs/api-reference/searches), which searches over an indexed file to obtain the relevant sections which can be included in the context, following by a question and answering prompt given a specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'answers_with_ft'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39manswers_with_ft\u001b[39;00m \u001b[39mimport\u001b[39;00m create_context, answer_question\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m      4\u001b[0m     create_context(\n\u001b[0;32m      5\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhere did women\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms 4 x 100 metres relay event take place during the 2020 Summer Olympics?\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'answers_with_ft'"
     ]
    }
   ],
   "source": [
    "from answers_with_ft import create_context, answer_question\n",
    "\n",
    "print(\n",
    "    create_context(\n",
    "        \"Where did women's 4 x 100 metres relay event take place during the 2020 Summer Olympics?\",\n",
    "        olympics_search_fileid,\n",
    "        max_len=400,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m answer_question(\n\u001b[0;32m      2\u001b[0m     olympics_search_fileid,\n\u001b[0;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdavinci-instruct-beta-v3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWhere did women\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms 4 x 100 metres relay event take place during the 2020 Summer Olympics?\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'answer_question' is not defined"
     ]
    }
   ],
   "source": [
    "answer_question(\n",
    "    olympics_search_fileid,\n",
    "    \"davinci-instruct-beta-v3\",\n",
    "    \"Where did women's 4 x 100 metres relay event take place during the 2020 Summer Olympics?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we fine-tune the model for Q&A we'll be able to use it instead of [`davinci-instruct-beta-v3`](https://beta.openai.com/docs/engines/instruct-series-beta), to obtain better answers when the question can't be answered based on the context. We see a downside of [`davinci-instruct-beta-v3`](https://beta.openai.com/docs/engines/instruct-series-beta), which always attempts to answer the question, regardless of the relevant context being present or not. (Note the second question is asking about a future event, set in 2024.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m answer_question(\n\u001b[0;32m      2\u001b[0m     olympics_search_fileid,\n\u001b[0;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdavinci-instruct-beta-v3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWhere did women\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms 4 x 100 metres relay event take place during the 2048 Summer Olympics?\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     max_len\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'answer_question' is not defined"
     ]
    }
   ],
   "source": [
    "answer_question(\n",
    "    olympics_search_fileid,\n",
    "    \"davinci-instruct-beta-v3\",\n",
    "    \"Where did women's 4 x 100 metres relay event take place during the 2048 Summer Olympics?\",\n",
    "    max_len=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that davinci has a tendency to answer the question, even if the question can't be answered given the context provided. Note the question asked regarding 2048 Summer Olympics, which didn't happen yet, and the retrieved content has only returned results for 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 (Optional) Investigation into how likely the search endpoint is to return the relevant context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def check_context(\n",
    "    title, heading, question, max_len=1800, search_model=\"ada\", max_rerank=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the search model in retrieving the correct context\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    title: str\n",
    "        The title of the Wikipedia page\n",
    "    heading: str\n",
    "        The heading of the Wikipedia section\n",
    "    qusetion: str\n",
    "        The question\n",
    "    max_len: int\n",
    "        The maximum length of the context\n",
    "    search_model: str\n",
    "        The search model to use - `ada` is most cost effective\n",
    "    max_rerank: int\n",
    "        The maximum number of reranking documents to use the search model on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rank: int\n",
    "        The rank of the correct context\n",
    "    token_length: int\n",
    "        The number of tokens needed to obtain the correct context\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        results = openai.Engine(search_model).search(\n",
    "            search_model=search_model,\n",
    "            query=question,\n",
    "            max_rerank=max_rerank,\n",
    "            file=olympics_search_fileid,\n",
    "            return_metadata=True,\n",
    "        )\n",
    "        index = -1\n",
    "        returns = []\n",
    "        cur_len = 0\n",
    "        for result in results[\"data\"]:\n",
    "            cur_len += (\n",
    "                int(result[\"metadata\"]) + 4\n",
    "            )  # we add 4 tokens for the separator `\\n\\n###\\n\\n`\n",
    "            if cur_len > max_len:\n",
    "                break\n",
    "            returns.append(result[\"text\"])\n",
    "            res = result[\"text\"].split(\"\\n\")\n",
    "            if res[0] == title and res[1] == heading:\n",
    "                index = len(returns) - 1\n",
    "                break\n",
    "        return index, cur_len\n",
    "    except Exception as e:\n",
    "        # print (e)\n",
    "        return []\n",
    "\n",
    "\n",
    "print(\n",
    "    check_context(\n",
    "        \"Athletics at the 2020 Summer Olympics – Women's 4 × 100 metres relay\",\n",
    "        \"Summary\",\n",
    "        \"Where did women's 4 x 100 metres relay event take place during the 2020 Summer Olympics?\",\n",
    "        max_len=10000,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize the generated questions based on context to estimate how often we can retrieve the original context. These questions are noisy, so this is not a perfect estimate.\n",
    "\n",
    "Our questions and answers are prefixed with numbered bullet points, however due to the way they were generated, they are missing the first number, hence we add \"1.\" to the list of questions (and answers).\n",
    "\n",
    "We calculate the rank of the section retrieved using ada search, and the number of tokens in the context needed to retrieve the relevant section in full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ada_results \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\n\u001b[0;32m      2\u001b[0m     \u001b[39mlambda\u001b[39;00m x: [\n\u001b[0;32m      3\u001b[0m         check_context(\n\u001b[0;32m      4\u001b[0m             x\u001b[39m.\u001b[39mtitle,\n\u001b[0;32m      5\u001b[0m             x\u001b[39m.\u001b[39mheading,\n\u001b[0;32m      6\u001b[0m             q[\u001b[39m3\u001b[39m:],  \u001b[39m# remove the number prefix\u001b[39;00m\n\u001b[0;32m      7\u001b[0m             max_len\u001b[39m=\u001b[39m\u001b[39m1000000\u001b[39m,  \u001b[39m# set a large number to get the full context\u001b[39;00m\n\u001b[0;32m      8\u001b[0m             search_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mada\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m             max_rerank\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m,\n\u001b[0;32m     10\u001b[0m         )\n\u001b[0;32m     11\u001b[0m         \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m (x\u001b[39m.\u001b[39mquestions)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# split the questions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(q) \u001b[39m>\u001b[39m \u001b[39m10\u001b[39m  \u001b[39m# remove the empty questions\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     ],\n\u001b[0;32m     14\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m ada_results\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "ada_results = df.apply(\n",
    "    lambda x: [\n",
    "        check_context(\n",
    "            x.title,\n",
    "            x.heading,\n",
    "            q[3:],  # remove the number prefix\n",
    "            max_len=1000000,  # set a large number to get the full context\n",
    "            search_model=\"ada\",\n",
    "            max_rerank=200,\n",
    "        )\n",
    "        for q in (x.questions).split(\"\\n\")  # split the questions\n",
    "        if len(q) > 10  # remove the empty questions\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "ada_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([ada_results], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m out\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mada\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m out\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39molympics-data/search_engine_results.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "out = pd.concat([ada_results], axis=1)\n",
    "out.columns = [\"ada\"]\n",
    "out.to_csv(\"olympics-data/search_engine_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 18\u001b[0m\n\u001b[0;32m      8\u001b[0m     cols \u001b[39m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m         pd\u001b[39m.\u001b[39mDataFrame(out[name]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m     10\u001b[0m         \u001b[39m.\u001b[39mstack()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m out\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m     14\u001b[0m     ]\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat(cols, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m out_expanded \u001b[39m=\u001b[39m expand_lists(out)\n\u001b[0;32m     19\u001b[0m out_expanded[\u001b[39m\"\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m out_expanded\u001b[39m.\u001b[39mada\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m x \u001b[39m!=\u001b[39m [] \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     20\u001b[0m out_expanded[\u001b[39m\"\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m out_expanded\u001b[39m.\u001b[39mada\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m x \u001b[39m!=\u001b[39m [] \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "def expand_lists(out):\n",
    "    \"\"\"\n",
    "    Expand a pandas series containing lists into a series, where each list element becomes a value on its own\n",
    "\n",
    "    Input is a row per paragraph, which has multiple questions\n",
    "    Output is a row per question\n",
    "    \"\"\"\n",
    "    cols = [\n",
    "        pd.DataFrame(out[name].tolist())\n",
    "        .stack()\n",
    "        .reset_index(level=1, drop=True)\n",
    "        .rename(name)\n",
    "        for name in out.columns\n",
    "    ]\n",
    "    return pd.concat(cols, axis=1)\n",
    "\n",
    "\n",
    "out_expanded = expand_lists(out)\n",
    "out_expanded[\"rank\"] = out_expanded.ada.apply(lambda x: x[0] if x != [] else -2)\n",
    "out_expanded[\"tokens\"] = out_expanded.ada.apply(lambda x: x[1] if x != [] else -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_expanded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m within_2k \u001b[39m=\u001b[39m (out_expanded\u001b[39m.\u001b[39mtokens \u001b[39m<\u001b[39m \u001b[39m2000\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m      3\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mwithin_2k\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% of relevant paragraphs are retrieved within the first 2k tokens\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_expanded' is not defined"
     ]
    }
   ],
   "source": [
    "within_2k = (out_expanded.tokens < 2000).mean()\n",
    "print(\n",
    "    f\"{within_2k*100:.1f}% of relevant paragraphs are retrieved within the first 2k tokens\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant context can be obtained 74% of the time on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_expanded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m outside_200 \u001b[39m=\u001b[39m (out_expanded[\u001b[39m\"\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m      3\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moutside_200\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% of relevant paragraphs are not retrieved within the first 200 results\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_expanded' is not defined"
     ]
    }
   ],
   "source": [
    "outside_200 = (out_expanded[\"rank\"] == -1).mean()\n",
    "print(\n",
    "    f\"{outside_200*100:.1f}% of relevant paragraphs are not retrieved within the first 200 results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4% of the time, this is due to the keyword search part of the search algorithm not retrieving the relevant context within the first 200 results.\n",
    "18.3% of the time this is due to the semantic search not placing the relevant context within the first 2000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# plot a histogram, and add axis descriptions and title\u001b[39;00m\n\u001b[0;32m      4\u001b[0m out_expanded[(out_expanded[\u001b[39m\"\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (out_expanded[\u001b[39m\"\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m30\u001b[39m)][\u001b[39m\"\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mhist(\n\u001b[0;32m      5\u001b[0m     bins\u001b[39m=\u001b[39m\u001b[39m29\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot a histogram, and add axis descriptions and title\n",
    "out_expanded[(out_expanded[\"rank\"] >= 0) & (out_expanded[\"rank\"] < 30)][\"rank\"].hist(\n",
    "    bins=29\n",
    ")\n",
    "plt.xlabel(\"rank\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Histogram of ranks of retrieved paragraphs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_expanded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out_expanded[(out_expanded\u001b[39m.\u001b[39mtokens \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (out_expanded\u001b[39m.\u001b[39mtokens \u001b[39m<\u001b[39m \u001b[39m2000\u001b[39m)][\u001b[39m\"\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mhist(\n\u001b[0;32m      2\u001b[0m     bins\u001b[39m=\u001b[39m\u001b[39m29\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_expanded' is not defined"
     ]
    }
   ],
   "source": [
    "out_expanded[(out_expanded.tokens >= 0) & (out_expanded.tokens < 2000)][\"tokens\"].hist(\n",
    "    bins=29\n",
    ")\n",
    "plt.xlabel(\"tokens\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Histogram of the number of minimum tokens needed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the context is most likely to be returned as one of the first results, and most likely to be returned within the first 200-500 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_expanded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# normalized value_counts\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m out_expanded[\u001b[39m\"\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue_counts(normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39msort_index()[:\u001b[39m13\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_expanded' is not defined"
     ]
    }
   ],
   "source": [
    "# normalized value_counts\n",
    "out_expanded[\"rank\"].value_counts(normalize=True).sort_index()[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probabilities of the relevant context being returned at each rank. (-2 means a processing error, -1 means the rank is >200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb9817b186a29e4e9713184d901f26c1ee05ad25243d878baff7f31bb1fef480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
