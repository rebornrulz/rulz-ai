{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Tuning with GPT-4\n",
    "\n",
    "This notebook is developed to produce the pie chart html/figure in the GPT-4-LLM paper. It analyzes the GPT4 output by following the instructions.\n",
    "\n",
    "```\n",
    "``Instruction Tuning with GPT-4'' (https://arxiv.org/abs/2304.03277)\n",
    "Baolin Peng*, Chunyuan Li*, Pengcheng He*, Michel Galley, Jianfeng Gao (*Equal Contribution)\n",
    "```\n",
    "\n",
    "- Project: https://instruction-tuning-with-gpt-4.github.io/\n",
    "- Github Repo: https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM\n",
    "\n",
    "Please submit an issue in the github repo, if you have any questions.\n",
    "\n",
    "\n",
    "\n",
    "*Note: The original script from [self-instruct repo](https://github.com/yizhongw/self-instruct/blob/main/self_instruct/instruction_visualize.ipynb). The script uses Berkeley Neural Parser to parse the generated instructions, and visualize the results using Plotly. Please make sure to install benepar following their documentation [here](https://github.com/nikitakit/self-attentive-parser#installation).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'benepar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbenepar\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpython -m spacy download en_core_web_md\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_md\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'benepar'"
     ]
    }
   ],
   "source": [
    "import benepar, spacy\n",
    "\n",
    "!python -m spacy download en_core_web_md\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(\"The time for action is now. It's never too late to do something.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Verb-Noun Pairs for GPT4 Output\n",
    "\n",
    ":warning: Warning: It takes 20 minutes to run the entire pre-processing, and save it into a csv file. You consider to skip processing, and load our pre-process Verb-Noun CSV file in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('write', 'story')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_root_verb_and_its_dobj(tree_root):\n",
    "    # first check if the current node and its children satisfy the condition\n",
    "    if tree_root.pos_ == \"VERB\":\n",
    "        for child in tree_root.children:\n",
    "            if child.dep_ == \"dobj\" and child.pos_ == \"NOUN\":\n",
    "                return tree_root.lemma_, child.lemma_\n",
    "        return tree_root.lemma_, None\n",
    "    # if not, check its children\n",
    "    for child in tree_root.children:\n",
    "        return find_root_verb_and_its_dobj(child)\n",
    "    # if no children satisfy the condition, return None\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def find_root_verb_and_its_dobj_in_string(s):\n",
    "    doc = nlp(s)\n",
    "    first_sent = list(doc.sents)[0]\n",
    "    return find_root_verb_and_its_dobj(first_sent.root)\n",
    "\n",
    "\n",
    "find_root_verb_and_its_dobj_in_string(\"Write me a story about education.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51749/51749 [19:25<00:00, 44.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "\n",
    "generated_data_path = \"data/gpt4_alpaca_data_0329.json\"\n",
    "\n",
    "with open(generated_data_path, \"r\") as fin:\n",
    "    gpt4_machine_generated_tasks = json.load(fin)\n",
    "\n",
    "# print(gpt4_machine_generated_tasks[0])\n",
    "\n",
    "instruction_outputs = set(\n",
    "    [task[\"output\"] for task in gpt4_machine_generated_tasks]\n",
    ")  # if you are interested in studying the instructions, please change the task key\n",
    "print(len(instruction_outputs))\n",
    "\n",
    "raw_phrases = []\n",
    "for out in tqdm.tqdm(instruction_outputs):\n",
    "    try:\n",
    "        verb, noun = find_root_verb_and_its_dobj_in_string(out)\n",
    "        raw_phrases.append({\"verb\": verb, \"noun\": noun, \"instruction_output\": out})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_phrases)\n",
    "raw_phrases = pd.DataFrame(raw_phrases)\n",
    "raw_phrases.to_csv(r\"data/gpt4_alpaca_verb_noun_output.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pie Chart Creation on Verb-Noun\n",
    "\n",
    "Load our pre-process Verb-Noun CSV file, and create the html file with plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_phrases = pd.read_csv(r\"data/gpt4_alpaca_verb_noun_output.csv\")\n",
    "raw_phrases = pd.DataFrame(raw_phrases)\n",
    "phrases = pd.DataFrame(raw_phrases).dropna()\n",
    "count_list = (\n",
    "    phrases[[\"verb\", \"noun\"]]\n",
    "    .groupby([\"verb\", \"noun\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5229"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_list)\n",
    "# count_list[:25]\n",
    "\n",
    "# count_list[:25].plot.barh()\n",
    "# plt.ylabel('verb, noun')\n",
    "# plt.xlabel('frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>noun</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bring</td>\n",
       "      <td>change</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bring</td>\n",
       "      <td>benefit</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bring</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bring</td>\n",
       "      <td>hope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contain</td>\n",
       "      <td>error</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>use</td>\n",
       "      <td>function</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>write</td>\n",
       "      <td>letter</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>write</td>\n",
       "      <td>novel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>write</td>\n",
       "      <td>book</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>write</td>\n",
       "      <td>report</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       verb      noun  count\n",
       "0     bring    change     13\n",
       "1     bring   benefit      7\n",
       "2     bring       joy      3\n",
       "3     bring      hope      2\n",
       "4   contain     error     14\n",
       "..      ...       ...    ...\n",
       "75      use  function     11\n",
       "76    write    letter     22\n",
       "77    write     novel      8\n",
       "78    write      book      7\n",
       "79    write    report      5\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_verbs = phrases[[\"verb\"]].groupby([\"verb\"]).size().nlargest(20).reset_index()\n",
    "\n",
    "df = phrases[phrases[\"verb\"].isin(top_verbs[\"verb\"].tolist())]\n",
    "# df = df[~df[\"noun\"].isin([\"I\", \"what\"])]\n",
    "# df = phrases\n",
    "# df[~df[\"verb\"].isin(top_verbs[\"verb\"].tolist())][\"verb\"] = \"other\"\n",
    "# df[~df[\"verb\"].isin(top_verbs[\"verb\"].tolist())][\"noun\"] = \"other\"\n",
    "df = (\n",
    "    df.groupby([\"verb\", \"noun\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"count\"})\n",
    "    .sort_values(by=[\"count\"], ascending=False)\n",
    ")\n",
    "# df = df[df[\"count\"] > 10]\n",
    "df = (\n",
    "    df.groupby(\"verb\")\n",
    "    .apply(lambda x: x.sort_values(\"count\", ascending=False).head(4))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# df[\"blank\"] = \"ROOT\"\n",
    "# df = phrases.groupby([\"verb\", \"noun\"]).size().sort_values(ascending=False).head(5).reset_index().rename(columns={0: \"count\"})\n",
    "\n",
    "df = df[df[\"count\"] > 10]\n",
    "fig = px.sunburst(df, path=[\"verb\", \"noun\"], values=\"count\")\n",
    "# fig.update_layout(uniformtext=dict(minsize=10, mode='hide'))\n",
    "fig.update_layout(\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    font_family=\"Times New Roman\",\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_html(\"output/gpt4_alpaca_verb_noun_output.html\")\n",
    "# fig.savefig(\"output/verb_noun.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "364c1b690e879c5ffe4e7bee613e5b5479420b51b03f29835176bef56dfadb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
