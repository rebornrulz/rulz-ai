{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Tuning with GPT-4\n",
    "\n",
    "This notebook is developed to produce the pie chart html/figure in the GPT-4-LLM paper. It analyzes the GPT4 output by following the instructions.\n",
    "\n",
    "```\n",
    "``Instruction Tuning with GPT-4'' (https://arxiv.org/abs/2304.03277)\n",
    "Baolin Peng*, Chunyuan Li*, Pengcheng He*, Michel Galley, Jianfeng Gao (*Equal Contribution)\n",
    "```\n",
    "\n",
    "- Project: https://instruction-tuning-with-gpt-4.github.io/\n",
    "- Github Repo: https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM\n",
    "\n",
    "Please submit an issue in the github repo, if you have any questions.\n",
    "\n",
    "\n",
    "\n",
    "*Note: The original script from [self-instruct repo](https://github.com/yizhongw/self-instruct/blob/main/self_instruct/instruction_visualize.ipynb). The script uses Berkeley Neural Parser to parse the generated instructions, and visualize the results using Plotly. Please make sure to install benepar following their documentation [here](https://github.com/nikitakit/self-attentive-parser#installation).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "import benepar, spacy\n",
    "\n",
    "%python -m spacy download en_core_web_md\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(\"The time for action is now. It's never too late to do something.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Verb-Noun Pairs for GPT4 Output\n",
    "\n",
    ":warning: Warning: It takes 20 minutes to run the entire pre-processing, and save it into a csv file. You consider to skip processing, and load our pre-process Verb-Noun CSV file in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Artificial Intelligence\\rulz-ai\\colabs\\gpt-4\\.ipynb_checkpoints\\instruction_visualize_gpt4-checkpoint.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     first_sent \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(doc\u001b[39m.\u001b[39msents)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find_root_verb_and_its_dobj(first_sent\u001b[39m.\u001b[39mroot)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m find_root_verb_and_its_dobj_in_string(\u001b[39m\"\u001b[39;49m\u001b[39mWrite me a story about education.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32md:\\Artificial Intelligence\\rulz-ai\\colabs\\gpt-4\\.ipynb_checkpoints\\instruction_visualize_gpt4-checkpoint.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_root_verb_and_its_dobj_in_string\u001b[39m(s):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(s)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     first_sent \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(doc\u001b[39m.\u001b[39msents)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find_root_verb_and_its_dobj(first_sent\u001b[39m.\u001b[39mroot)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "def find_root_verb_and_its_dobj(tree_root):\n",
    "    # first check if the current node and its children satisfy the condition\n",
    "    if tree_root.pos_ == \"VERB\":\n",
    "        for child in tree_root.children:\n",
    "            if child.dep_ == \"dobj\" and child.pos_ == \"NOUN\":\n",
    "                return tree_root.lemma_, child.lemma_\n",
    "        return tree_root.lemma_, None\n",
    "    # if not, check its children\n",
    "    for child in tree_root.children:\n",
    "        return find_root_verb_and_its_dobj(child)\n",
    "    # if no children satisfy the condition, return None\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def find_root_verb_and_its_dobj_in_string(s):\n",
    "    doc = nlp(s)\n",
    "    first_sent = list(doc.sents)[0]\n",
    "    return find_root_verb_and_its_dobj(first_sent.root)\n",
    "\n",
    "\n",
    "find_root_verb_and_its_dobj_in_string(\"Write me a story about education.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/gpt4_alpaca_data_0329.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Artificial Intelligence\\rulz-ai\\colabs\\gpt-4\\.ipynb_checkpoints\\instruction_visualize_gpt4-checkpoint.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m generated_data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/gpt4_alpaca_data_0329.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(generated_data_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     gpt4_machine_generated_tasks \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(fin)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Artificial%20Intelligence/rulz-ai/colabs/gpt-4/.ipynb_checkpoints/instruction_visualize_gpt4-checkpoint.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# print(gpt4_machine_generated_tasks[0])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rebor\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/gpt4_alpaca_data_0329.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "\n",
    "generated_data_path = \"data/gpt4_alpaca_data_0329.json\"\n",
    "\n",
    "with open(generated_data_path, \"r\") as fin:\n",
    "    gpt4_machine_generated_tasks = json.load(fin)\n",
    "\n",
    "# print(gpt4_machine_generated_tasks[0])\n",
    "\n",
    "instruction_outputs = set(\n",
    "    [task[\"output\"] for task in gpt4_machine_generated_tasks]\n",
    ")  # if you are interested in studying the instructions, please change the task key\n",
    "print(len(instruction_outputs))\n",
    "\n",
    "raw_phrases = []\n",
    "for out in tqdm.tqdm(instruction_outputs):\n",
    "    try:\n",
    "        verb, noun = find_root_verb_and_its_dobj_in_string(out)\n",
    "        raw_phrases.append({\"verb\": verb, \"noun\": noun, \"instruction_output\": out})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_phrases)\n",
    "raw_phrases = pd.DataFrame(raw_phrases)\n",
    "raw_phrases.to_csv(r\"data/gpt4_alpaca_verb_noun_output.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pie Chart Creation on Verb-Noun\n",
    "\n",
    "Load our pre-process Verb-Noun CSV file, and create the html file with plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_phrases = pd.read_csv(r\"data/gpt4_alpaca_verb_noun_output.csv\")\n",
    "raw_phrases = pd.DataFrame(raw_phrases)\n",
    "phrases = pd.DataFrame(raw_phrases).dropna()\n",
    "count_list = (\n",
    "    phrases[[\"verb\", \"noun\"]]\n",
    "    .groupby([\"verb\", \"noun\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5229"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_list)\n",
    "# count_list[:25]\n",
    "\n",
    "# count_list[:25].plot.barh()\n",
    "# plt.ylabel('verb, noun')\n",
    "# plt.xlabel('frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>noun</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bring</td>\n",
       "      <td>change</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bring</td>\n",
       "      <td>benefit</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bring</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bring</td>\n",
       "      <td>hope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contain</td>\n",
       "      <td>error</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>use</td>\n",
       "      <td>function</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>write</td>\n",
       "      <td>letter</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>write</td>\n",
       "      <td>novel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>write</td>\n",
       "      <td>book</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>write</td>\n",
       "      <td>report</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       verb      noun  count\n",
       "0     bring    change     13\n",
       "1     bring   benefit      7\n",
       "2     bring       joy      3\n",
       "3     bring      hope      2\n",
       "4   contain     error     14\n",
       "..      ...       ...    ...\n",
       "75      use  function     11\n",
       "76    write    letter     22\n",
       "77    write     novel      8\n",
       "78    write      book      7\n",
       "79    write    report      5\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_verbs = phrases[[\"verb\"]].groupby([\"verb\"]).size().nlargest(20).reset_index()\n",
    "\n",
    "df = phrases[phrases[\"verb\"].isin(top_verbs[\"verb\"].tolist())]\n",
    "# df = df[~df[\"noun\"].isin([\"I\", \"what\"])]\n",
    "# df = phrases\n",
    "# df[~df[\"verb\"].isin(top_verbs[\"verb\"].tolist())][\"verb\"] = \"other\"\n",
    "# df[~df[\"verb\"].isin(top_verbs[\"verb\"].tolist())][\"noun\"] = \"other\"\n",
    "df = (\n",
    "    df.groupby([\"verb\", \"noun\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"count\"})\n",
    "    .sort_values(by=[\"count\"], ascending=False)\n",
    ")\n",
    "# df = df[df[\"count\"] > 10]\n",
    "df = (\n",
    "    df.groupby(\"verb\")\n",
    "    .apply(lambda x: x.sort_values(\"count\", ascending=False).head(4))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# df[\"blank\"] = \"ROOT\"\n",
    "# df = phrases.groupby([\"verb\", \"noun\"]).size().sort_values(ascending=False).head(5).reset_index().rename(columns={0: \"count\"})\n",
    "\n",
    "df = df[df[\"count\"] > 10]\n",
    "fig = px.sunburst(df, path=[\"verb\", \"noun\"], values=\"count\")\n",
    "# fig.update_layout(uniformtext=dict(minsize=10, mode='hide'))\n",
    "fig.update_layout(\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    font_family=\"Times New Roman\",\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_html(\"output/gpt4_alpaca_verb_noun_output.html\")\n",
    "# fig.savefig(\"output/verb_noun.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "364c1b690e879c5ffe4e7bee613e5b5479420b51b03f29835176bef56dfadb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
