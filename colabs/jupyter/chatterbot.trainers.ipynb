{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "\n",
        "# Create a new trainer for the chatbot\n",
        "trainer = ChatterBotCorpusTrainer(chatbot)\n",
        "\n",
        "# Train based on the english corpus\n",
        "trainer.train(\"chatterbot.corpus.english\")\n",
        "\n",
        "# Train based on english greetings corpus\n",
        "trainer.train(\"chatterbot.corpus.english.greetings\")\n",
        "\n",
        "# Train based on the english conversations corpus\n",
        "trainer.train(\"chatterbot.corpus.english.conversations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1680612486.py, line 77)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 77\u001b[1;36m\u001b[0m\n\u001b[1;33m    [docs]class ListTrainer(Trainer):\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "from dateutil import parser as date_parser\n",
        "from chatterbot.conversation import Statement\n",
        "from chatterbot.tagging import PosLemmaTagger\n",
        "from chatterbot import utils\n",
        "\n",
        "\n",
        "class Trainer(object):\n",
        "    \"\"\"\n",
        "    Base class for all other trainer classes.\n",
        "\n",
        "    :param boolean show_training_progress: Show progress indicators for the\n",
        "           trainer. The environment variable ``CHATTERBOT_SHOW_TRAINING_PROGRESS``\n",
        "           can also be set to control this. ``show_training_progress`` will override\n",
        "           the environment variable if it is set.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chatbot, **kwargs):\n",
        "        self.chatbot = chatbot\n",
        "\n",
        "        environment_default = os.getenv('CHATTERBOT_SHOW_TRAINING_PROGRESS', True)\n",
        "        self.show_training_progress = kwargs.get(\n",
        "            'show_training_progress',\n",
        "            environment_default\n",
        "        )\n",
        "\n",
        "    def get_preprocessed_statement(self, input_statement):\n",
        "        \"\"\"\n",
        "        Preprocess the input statement.\n",
        "        \"\"\"\n",
        "        for preprocessor in self.chatbot.preprocessors:\n",
        "            input_statement = preprocessor(input_statement)\n",
        "\n",
        "        return input_statement\n",
        "\n",
        "    def train(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        This method must be overridden by a child class.\n",
        "        \"\"\"\n",
        "        raise self.TrainerInitializationException()\n",
        "\n",
        "    class TrainerInitializationException(Exception):\n",
        "        \"\"\"\n",
        "        Exception raised when a base class has not overridden\n",
        "        the required methods on the Trainer base class.\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, message=None):\n",
        "            default = (\n",
        "                'A training class must be specified before calling train(). '\n",
        "                'See http://chatterbot.readthedocs.io/en/stable/training.html'\n",
        "            )\n",
        "            super().__init__(message or default)\n",
        "\n",
        "    def _generate_export_data(self):\n",
        "        result = []\n",
        "        for statement in self.chatbot.storage.filter():\n",
        "            if statement.in_response_to:\n",
        "                result.append([statement.in_response_to, statement.text])\n",
        "\n",
        "        return result\n",
        "\n",
        "    def export_for_training(self, file_path='./export.json'):\n",
        "        \"\"\"\n",
        "        Create a file from the database that can be used to\n",
        "        train other chat bots.\n",
        "        \"\"\"\n",
        "        import json\n",
        "        export = {'conversations': self._generate_export_data()}\n",
        "        with open(file_path, 'w+', encoding='utf8') as jsonfile:\n",
        "            json.dump(export, jsonfile, ensure_ascii=False)\n",
        "\n",
        "\n",
        "[docs]class ListTrainer(Trainer):\n",
        "    \"\"\"\n",
        "    Allows a chat bot to be trained using a list of strings\n",
        "    where the list represents a conversation.\n",
        "    \"\"\"\n",
        "\n",
        "    def train(self, conversation):\n",
        "        \"\"\"\n",
        "        Train the chat bot based on the provided list of\n",
        "        statements that represents a single conversation.\n",
        "        \"\"\"\n",
        "        previous_statement_text = None\n",
        "        previous_statement_search_text = ''\n",
        "\n",
        "        statements_to_create = []\n",
        "\n",
        "        for conversation_count, text in enumerate(conversation):\n",
        "            if self.show_training_progress:\n",
        "                utils.print_progress_bar(\n",
        "                    'List Trainer',\n",
        "                    conversation_count + 1, len(conversation)\n",
        "                )\n",
        "\n",
        "            statement_search_text = self.chatbot.storage.tagger.get_text_index_string(text)\n",
        "\n",
        "            statement = self.get_preprocessed_statement(\n",
        "                Statement(\n",
        "                    text=text,\n",
        "                    search_text=statement_search_text,\n",
        "                    in_response_to=previous_statement_text,\n",
        "                    search_in_response_to=previous_statement_search_text,\n",
        "                    conversation='training'\n",
        "                )\n",
        "            )\n",
        "\n",
        "            previous_statement_text = statement.text\n",
        "            previous_statement_search_text = statement_search_text\n",
        "\n",
        "            statements_to_create.append(statement)\n",
        "\n",
        "        self.chatbot.storage.create_many(statements_to_create)\n",
        "\n",
        "\n",
        "\n",
        "[docs]class ChatterBotCorpusTrainer(Trainer):\n",
        "    \"\"\"\n",
        "    Allows the chat bot to be trained using data from the\n",
        "    ChatterBot dialog corpus.\n",
        "    \"\"\"\n",
        "\n",
        "    def train(self, *corpus_paths):\n",
        "        from chatterbot.corpus import load_corpus, list_corpus_files\n",
        "\n",
        "        data_file_paths = []\n",
        "\n",
        "        # Get the paths to each file the bot will be trained with\n",
        "        for corpus_path in corpus_paths:\n",
        "            data_file_paths.extend(list_corpus_files(corpus_path))\n",
        "\n",
        "        for corpus, categories, file_path in load_corpus(*data_file_paths):\n",
        "\n",
        "            statements_to_create = []\n",
        "\n",
        "            # Train the chat bot with each statement and response pair\n",
        "            for conversation_count, conversation in enumerate(corpus):\n",
        "\n",
        "                if self.show_training_progress:\n",
        "                    utils.print_progress_bar(\n",
        "                        'Training ' + str(os.path.basename(file_path)),\n",
        "                        conversation_count + 1,\n",
        "                        len(corpus)\n",
        "                    )\n",
        "\n",
        "                previous_statement_text = None\n",
        "                previous_statement_search_text = ''\n",
        "\n",
        "                for text in conversation:\n",
        "\n",
        "                    statement_search_text = self.chatbot.storage.tagger.get_text_index_string(text)\n",
        "\n",
        "                    statement = Statement(\n",
        "                        text=text,\n",
        "                        search_text=statement_search_text,\n",
        "                        in_response_to=previous_statement_text,\n",
        "                        search_in_response_to=previous_statement_search_text,\n",
        "                        conversation='training'\n",
        "                    )\n",
        "\n",
        "                    statement.add_tags(*categories)\n",
        "\n",
        "                    statement = self.get_preprocessed_statement(statement)\n",
        "\n",
        "                    previous_statement_text = statement.text\n",
        "                    previous_statement_search_text = statement_search_text\n",
        "\n",
        "                    statements_to_create.append(statement)\n",
        "\n",
        "            if statements_to_create:\n",
        "                self.chatbot.storage.create_many(statements_to_create)\n",
        "\n",
        "\n",
        "\n",
        "[docs]class UbuntuCorpusTrainer(Trainer):\n",
        "    \"\"\"\n",
        "    Allow chatbots to be trained with the data from the Ubuntu Dialog Corpus.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chatbot, **kwargs):\n",
        "        super().__init__(chatbot, **kwargs)\n",
        "        home_directory = os.path.expanduser('~')\n",
        "\n",
        "        self.data_download_url = kwargs.get(\n",
        "            'ubuntu_corpus_data_download_url',\n",
        "            'http://cs.mcgill.ca/~jpineau/datasets/ubuntu-corpus-1.0/ubuntu_dialogs.tgz'\n",
        "        )\n",
        "\n",
        "        self.data_directory = kwargs.get(\n",
        "            'ubuntu_corpus_data_directory',\n",
        "            os.path.join(home_directory, 'ubuntu_data')\n",
        "        )\n",
        "\n",
        "        self.extracted_data_directory = os.path.join(\n",
        "            self.data_directory, 'ubuntu_dialogs'\n",
        "        )\n",
        "\n",
        "        # Create the data directory if it does not already exist\n",
        "        if not os.path.exists(self.data_directory):\n",
        "            os.makedirs(self.data_directory)\n",
        "\n",
        "    def is_downloaded(self, file_path):\n",
        "        \"\"\"\n",
        "        Check if the data file is already downloaded.\n",
        "        \"\"\"\n",
        "        if os.path.exists(file_path):\n",
        "            self.chatbot.logger.info('File is already downloaded')\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def is_extracted(self, file_path):\n",
        "        \"\"\"\n",
        "        Check if the data file is already extracted.\n",
        "        \"\"\"\n",
        "\n",
        "        if os.path.isdir(file_path):\n",
        "            self.chatbot.logger.info('File is already extracted')\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def download(self, url, show_status=True):\n",
        "        \"\"\"\n",
        "        Download a file from the given url.\n",
        "        Show a progress indicator for the download status.\n",
        "        Based on: http://stackoverflow.com/a/15645088/1547223\n",
        "        \"\"\"\n",
        "        import requests\n",
        "\n",
        "        file_name = url.split('/')[-1]\n",
        "        file_path = os.path.join(self.data_directory, file_name)\n",
        "\n",
        "        # Do not download the data if it already exists\n",
        "        if self.is_downloaded(file_path):\n",
        "            return file_path\n",
        "\n",
        "        with open(file_path, 'wb') as open_file:\n",
        "            print('Downloading %s' % url)\n",
        "            response = requests.get(url, stream=True)\n",
        "            total_length = response.headers.get('content-length')\n",
        "\n",
        "            if total_length is None:\n",
        "                # No content length header\n",
        "                open_file.write(response.content)\n",
        "            else:\n",
        "                download = 0\n",
        "                total_length = int(total_length)\n",
        "                for data in response.iter_content(chunk_size=4096):\n",
        "                    download += len(data)\n",
        "                    open_file.write(data)\n",
        "                    if show_status:\n",
        "                        done = int(50 * download / total_length)\n",
        "                        sys.stdout.write('\\r[%s%s]' % ('=' * done, ' ' * (50 - done)))\n",
        "                        sys.stdout.flush()\n",
        "\n",
        "            # Add a new line after the download bar\n",
        "            sys.stdout.write('\\n')\n",
        "\n",
        "        print('Download location: %s' % file_path)\n",
        "        return file_path\n",
        "\n",
        "    def extract(self, file_path):\n",
        "        \"\"\"\n",
        "        Extract a tar file at the specified file path.\n",
        "        \"\"\"\n",
        "        import tarfile\n",
        "\n",
        "        print('Extracting {}'.format(file_path))\n",
        "\n",
        "        if not os.path.exists(self.extracted_data_directory):\n",
        "            os.makedirs(self.extracted_data_directory)\n",
        "\n",
        "        def track_progress(members):\n",
        "            sys.stdout.write('.')\n",
        "            for member in members:\n",
        "                # This will be the current file being extracted\n",
        "                yield member\n",
        "\n",
        "        with tarfile.open(file_path) as tar:\n",
        "            tar.extractall(path=self.extracted_data_directory, members=track_progress(tar))\n",
        "\n",
        "        self.chatbot.logger.info('File extracted to {}'.format(self.extracted_data_directory))\n",
        "\n",
        "        return True\n",
        "\n",
        "    def train(self):\n",
        "        import glob\n",
        "\n",
        "        tagger = PosLemmaTagger(language=self.chatbot.storage.tagger.language)\n",
        "\n",
        "        # Download and extract the Ubuntu dialog corpus if needed\n",
        "        corpus_download_path = self.download(self.data_download_url)\n",
        "\n",
        "        # Extract if the directory does not already exist\n",
        "        if not self.is_extracted(self.extracted_data_directory):\n",
        "            self.extract(corpus_download_path)\n",
        "\n",
        "        extracted_corpus_path = os.path.join(\n",
        "            self.extracted_data_directory,\n",
        "            '**', '**', '*.tsv'\n",
        "        )\n",
        "\n",
        "        def chunks(items, items_per_chunk):\n",
        "            for start_index in range(0, len(items), items_per_chunk):\n",
        "                end_index = start_index + items_per_chunk\n",
        "                yield items[start_index:end_index]\n",
        "\n",
        "        file_list = glob.glob(extracted_corpus_path)\n",
        "\n",
        "        file_groups = tuple(chunks(file_list, 10000))\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for tsv_files in file_groups:\n",
        "\n",
        "            statements_from_file = []\n",
        "\n",
        "            for tsv_file in tsv_files:\n",
        "                with open(tsv_file, 'r', encoding='utf-8') as tsv:\n",
        "                    reader = csv.reader(tsv, delimiter='\\t')\n",
        "\n",
        "                    previous_statement_text = None\n",
        "                    previous_statement_search_text = ''\n",
        "\n",
        "                    for row in reader:\n",
        "                        if len(row) > 0:\n",
        "                            statement = Statement(\n",
        "                                text=row[3],\n",
        "                                in_response_to=previous_statement_text,\n",
        "                                conversation='training',\n",
        "                                created_at=date_parser.parse(row[0]),\n",
        "                                persona=row[1]\n",
        "                            )\n",
        "\n",
        "                            for preprocessor in self.chatbot.preprocessors:\n",
        "                                statement = preprocessor(statement)\n",
        "\n",
        "                            statement.search_text = tagger.get_text_index_string(statement.text)\n",
        "                            statement.search_in_response_to = previous_statement_search_text\n",
        "\n",
        "                            previous_statement_text = statement.text\n",
        "                            previous_statement_search_text = statement.search_text\n",
        "\n",
        "                            statements_from_file.append(statement)\n",
        "\n",
        "            self.chatbot.storage.create_many(statements_from_file)\n",
        "\n",
        "        print('Training took', time.time() - start_time, 'seconds.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
