{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Tuning with GPT-4\n",
    "\n",
    "This notebook is developed to produce the figures in the paper: \n",
    "\n",
    "```\n",
    "``Instruction Tuning with GPT-4'' (https://arxiv.org/abs/2304.03277)\n",
    "Baolin Peng*, Chunyuan Li*, Pengcheng He*, Michel Galley, Jianfeng Gao (*Equal Contribution)\n",
    "```\n",
    "\n",
    "- Project: https://instruction-tuning-with-gpt-4.github.io/\n",
    "- Github Repo: https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM\n",
    "\n",
    "Please submit an issue in the github repo, if you have any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compare the data stats of GPT4 and GPT3 for Alpaca instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m raw_phrases \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/gpt4_alpaca_verb_noun_output.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "raw_phrases = pd.read_csv(r\"data/gpt4_alpaca_verb_noun_output.csv\")\n",
    "raw_phrases = pd.DataFrame(raw_phrases)\n",
    "phrases = pd.DataFrame(raw_phrases).dropna()\n",
    "pd_count_gpt4 = (\n",
    "    phrases[[\"verb\", \"noun\"]]\n",
    "    .groupby([\"verb\", \"noun\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "raw_phrases = pd.read_csv(r\"data/alpaca_verb_noun_output.csv\")\n",
    "raw_phrases = pd.DataFrame(raw_phrases)\n",
    "phrases = pd.DataFrame(raw_phrases).dropna()\n",
    "pd_count_gpt3 = (\n",
    "    phrases[[\"verb\", \"noun\"]]\n",
    "    .groupby([\"verb\", \"noun\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd_count_gpt4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m top_k \u001b[39m=\u001b[39m \u001b[39m25\u001b[39m\n\u001b[0;32m      3\u001b[0m list_pair_gpt4, list_count_gpt4 \u001b[39m=\u001b[39m [], []\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m verb_noun_pair, count \u001b[39min\u001b[39;00m pd_count_gpt4[:top_k]\u001b[39m.\u001b[39mto_dict()\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m     list_pair_gpt4\u001b[39m.\u001b[39mappend(verb_noun_pair)\n\u001b[0;32m      6\u001b[0m     list_count_gpt4\u001b[39m.\u001b[39mappend(count)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd_count_gpt4' is not defined"
     ]
    }
   ],
   "source": [
    "top_k = 25\n",
    "\n",
    "list_pair_gpt4, list_count_gpt4 = [], []\n",
    "for verb_noun_pair, count in pd_count_gpt4[:top_k].to_dict().items():\n",
    "    list_pair_gpt4.append(verb_noun_pair)\n",
    "    list_count_gpt4.append(count)\n",
    "\n",
    "\n",
    "list_pair_gpt3, list_count_gpt3 = [], []\n",
    "for verb_noun_pair, count in pd_count_gpt3[:top_k].to_dict().items():\n",
    "    list_pair_gpt3.append(verb_noun_pair)\n",
    "    list_count_gpt3.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_count_gpt3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m list_count_gpt4\n\u001b[1;32m----> 2\u001b[0m list_count_gpt3\n\u001b[0;32m      4\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m4\u001b[39m)) \u001b[39m# Create matplotlib figure\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot(\u001b[39m111\u001b[39m) \u001b[39m# Create matplotlib axes\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list_count_gpt3' is not defined"
     ]
    }
   ],
   "source": [
    "list_count_gpt4\n",
    "list_count_gpt3\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))  # Create matplotlib figure\n",
    "\n",
    "ax = fig.add_subplot(111)  # Create matplotlib axes\n",
    "ax2 = ax.twinx()  # Create another axes that shares the same x-axis as ax.\n",
    "\n",
    "width = 0.5\n",
    "\n",
    "\n",
    "pd_count_gpt4[:top_k][::-1].plot(\n",
    "    kind=\"barh\", color=\"orange\", ax=ax, width=width, position=0, alpha=1.0\n",
    ")\n",
    "pd_count_gpt3[:top_k][::-1].plot(\n",
    "    kind=\"barh\", color=\"skyblue\", ax=ax2, width=width, position=2, alpha=1.0\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Frequency\", color=\"k\")\n",
    "ax.xaxis.set_label_coords(0.48, 0.06)\n",
    "\n",
    "ax.set_ylabel(\"\", color=\"k\")\n",
    "ax2.set_ylabel(\"\", color=\"k\")\n",
    "\n",
    "\n",
    "plt.text(\n",
    "    105,\n",
    "    4,\n",
    "    \"#Unique Verb-Noun Pairs \\n GPT4: 5229 \\n GPT3: 6133\",\n",
    "    color=\"k\",\n",
    "    fontsize=10,\n",
    "    bbox={\"facecolor\": \"oldlace\", \"alpha\": 0.5, \"pad\": 1, \"boxstyle\": \"round,pad=0.1\"},\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    -25,\n",
    "    -3.1,\n",
    "    \"GPT4\",\n",
    "    color=\"orange\",\n",
    "    fontsize=13,\n",
    "    bbox={\"facecolor\": \"oldlace\", \"alpha\": 0.5, \"pad\": 1, \"boxstyle\": \"round,pad=0.1\"},\n",
    ")\n",
    "plt.text(\n",
    "    190,\n",
    "    -2.9,\n",
    "    \"GPT3\",\n",
    "    color=\"skyblue\",\n",
    "    fontsize=13,\n",
    "    bbox={\"facecolor\": \"oldlace\", \"alpha\": 0.5, \"pad\": 1, \"boxstyle\": \"round,pad=0.1\"},\n",
    ")\n",
    "ax.xaxis.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.show()\n",
    "fig.savefig(\"output/cmp_freq_gpt3_gpt4.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "\n",
    "generated_data_path = \"data/gpt4_alpaca_data_0329.json\"\n",
    "\n",
    "machine_generated_tasks = []\n",
    "with open(generated_data_path, \"r\") as fin:\n",
    "    machine_generated_tasks = json.load(fin)\n",
    "gpt4_output_len = [len(task[\"output\"].split()) for task in machine_generated_tasks]\n",
    "\n",
    "generated_data_path = \"data/alpaca_data.json\"\n",
    "\n",
    "machine_generated_tasks = []\n",
    "with open(generated_data_path, \"r\") as fin:\n",
    "    machine_generated_tasks = json.load(fin)\n",
    "gpt3_output_len = [len(task[\"output\"].split()) for task in machine_generated_tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m7\u001b[39m,\u001b[39m1.5\u001b[39m)) \u001b[39m# Create matplotlib figure\u001b[39;00m\n\u001b[0;32m      5\u001b[0m bins \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m100\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(7, 1.5))  # Create matplotlib figure\n",
    "bins = np.linspace(0, 512, 100)\n",
    "\n",
    "plt.hist(gpt4_output_len, bins, alpha=0.5, label=\"GPT4\", color=\"orange\")\n",
    "plt.hist(gpt3_output_len, bins, alpha=0.5, label=\"GPT3\", color=\"skyblue\")\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.xlim(-4, 512)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.grid(True, linestyle=\"--\", alpha=1.0)\n",
    "\n",
    "plt.xlabel(\"Output Sequence Length\", fontsize=10)\n",
    "plt.ylabel(\"Frequency\", fontsize=11)\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "fig.savefig(\"output/cmp_seq_len_freq_gpt3_gpt4.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Comparison/Feedback Data Disitrution\n",
    "\n",
    "#### Three models: ['text-davinci-003', 'icm-1.3b', 'gpt4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m f_instructions \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(\u001b[39m\"\u001b[39m\u001b[39mdata/cmp_data_scores.json\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "f_instructions = open(\n",
    "    os.path.expanduser(\"data/cmp_data_scores.json\"), \"r\", encoding=\"utf-8\"\n",
    ")\n",
    "score_dict = json.load(f_instructions)\n",
    "\n",
    "print(score_dict.keys())\n",
    "min_num = 0\n",
    "for key, value in score_dict.items():\n",
    "    print(f\"{key} : {len(value)}\")\n",
    "    if min_num == 0:\n",
    "        min_num = len(value)\n",
    "    else:\n",
    "        if len(value) < min_num:\n",
    "            min_num = len(value)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4, 3))  # Create matplotlib figure\n",
    "scores = pd.DataFrame(\n",
    "    {\n",
    "        \"OPT-IML\": score_dict[\"icm-1.3b\"][:min_num],\n",
    "        \"GPT3.5\": score_dict[\"text-davinci-003\"][:min_num],\n",
    "        \"GPT4\": score_dict[\"gpt4\"][:min_num],\n",
    "    }\n",
    ")\n",
    "g = sns.displot(\n",
    "    data=scores,\n",
    "    kind=\"kde\",\n",
    "    fill=True,\n",
    "    palette=sns.color_palette(\"bright\")[:3],\n",
    "    height=2.0,\n",
    "    aspect=1.5,\n",
    "    legend=True,\n",
    ")\n",
    "\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(0.25, 0.95), title=\"\")\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax = plt.gca()\n",
    "plt.xlim(0, 11)\n",
    "plt.ylim(0.0, 1.5)\n",
    "plt.xlabel(\"Score\", fontsize=11)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"output/cmp_data_dist.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluation benchmark data analysis\n",
    "\n",
    "#### * 252 unseen user oriented instructions from self-instruct (https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/user_oriented_instructions.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m f_instructions \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexpanduser(\u001b[39m\"\u001b[39;49m\u001b[39mdata/user_oriented_instructions.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m motivation_apps \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m f_instructions:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/user_oriented_instructions.jsonl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "f_instructions = open(\n",
    "    os.path.expanduser(\"data/user_oriented_instructions.jsonl\"), \"r\", encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "motivation_apps = []\n",
    "for i in f_instructions:\n",
    "    app = json.loads(i)[\"motivation_app\"]\n",
    "    motivation_apps.append(app)\n",
    "\n",
    "\n",
    "motivation_apps = list(set(motivation_apps))\n",
    "print(\n",
    "    f\"The number of applications considered: {len(motivation_apps)} \\n {motivation_apps}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * 80 unseen instructions from Vicuna (https://github.com/lm-sys/FastChat/blob/main/fastchat/eval/table/question.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/vicuna_question_80.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m f_instructions \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexpanduser(\u001b[39m\"\u001b[39;49m\u001b[39mdata/vicuna_question_80.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m motivation_apps \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m f_instructions:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vicuna_question_80.jsonl'"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "f_instructions = open(\n",
    "    os.path.expanduser(\"data/vicuna_question_80.jsonl\"), \"r\", encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "motivation_apps = []\n",
    "for i in f_instructions:\n",
    "    app = json.loads(i)[\"category\"]\n",
    "    motivation_apps.append(app)\n",
    "\n",
    "\n",
    "motivation_apps = list(set(motivation_apps))\n",
    "print(f\"The number of domains considered: {len(motivation_apps)} \\n {motivation_apps}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pie Chart on the Human Evaluation Results\n",
    "\n",
    "The 252 instructions from self instruct is used\n",
    "\n",
    "#### * LLaMA-GPT4 vs GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m llama_gpt4_vs_gpt4 \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mHelpfulness\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mllama_gpt4_win\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.4278145695364238\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgpt4_win\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.4410596026490066\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTie\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.1311258278145695\u001b[39m}, \u001b[39m'\u001b[39m\u001b[39mHonesty\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mllama_gpt4_win\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.37880794701986753\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgpt4_win\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.3748344370860927\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTie\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.2463576158940397\u001b[39m}, \u001b[39m'\u001b[39m\u001b[39mHarmlessness\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mllama_gpt4_win\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.3165562913907285\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgpt4_win\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.3536423841059603\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTie\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.32980132450331123\u001b[39m}}\n\u001b[1;32m----> 4\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m9\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i, (k,v) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(llama_gpt4_vs_gpt4\u001b[39m.\u001b[39mitems()):\n\u001b[0;32m      7\u001b[0m     colors \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mskyblue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morange\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlightgreen\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "llama_gpt4_vs_gpt4 = {\n",
    "    \"Helpfulness\": {\n",
    "        \"llama_gpt4_win\": 0.4278145695364238,\n",
    "        \"gpt4_win\": 0.4410596026490066,\n",
    "        \"Tie\": 0.1311258278145695,\n",
    "    },\n",
    "    \"Honesty\": {\n",
    "        \"llama_gpt4_win\": 0.37880794701986753,\n",
    "        \"gpt4_win\": 0.3748344370860927,\n",
    "        \"Tie\": 0.2463576158940397,\n",
    "    },\n",
    "    \"Harmlessness\": {\n",
    "        \"llama_gpt4_win\": 0.3165562913907285,\n",
    "        \"gpt4_win\": 0.3536423841059603,\n",
    "        \"Tie\": 0.32980132450331123,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
    "\n",
    "for i, (k, v) in enumerate(llama_gpt4_vs_gpt4.items()):\n",
    "    colors = [\"skyblue\", \"orange\", \"lightgreen\"]\n",
    "    labels = [\n",
    "        f\" GPT4 \\n  {v['gpt4_win']*100:.2f}%\",\n",
    "        f\"LLaMA-GPT4 \\n {v['llama_gpt4_win']*100:.2f}%\",\n",
    "        f\" Tie \\n {v['Tie']*100:.2f}%\",\n",
    "    ]\n",
    "    axs[i].pie(\n",
    "        v.values(),\n",
    "        labels=labels,\n",
    "        colors=colors,\n",
    "        labeldistance=0.24,\n",
    "        wedgeprops={\"alpha\": 0.7},\n",
    "    )\n",
    "    axs[i].set_title(k, y=-0.01)\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.2)\n",
    "plt.rcParams.update({\"font.size\": 10})\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"output/pie_llama_gpt4_vs_gpt4.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * LLaMA-GPT4 vs Alpaca (LLaMA-GPT3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " llama_gpt3_vs_llam_gpt4 = { \"Helpfulness\":{ \"llama_gpt3_win\":0.19744318181818182, \"llama_gpt4_win\":0.5411931818181818, \"Tie\":0.26136363636363646 }, \"Honesty\":{ \"llama_gpt3_win\":0.31392045454545453, \"llama_gpt4_win\":0.2599431818181818, \"Tie\":0.42613636363636365 }, \"Harmlessness\":{ \"llama_gpt3_win\":0.25426136363636365, \"llama_gpt4_win\":0.16477272727272727, \"Tie\":0.5809659090909091 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m9\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i, (k,v) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(llama_gpt3_vs_llam_gpt4\u001b[39m.\u001b[39mitems()):\n\u001b[0;32m      4\u001b[0m     colors \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mskyblue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morange\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlightgreen\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
    "\n",
    "for i, (k, v) in enumerate(llama_gpt3_vs_llam_gpt4.items()):\n",
    "    colors = [\"skyblue\", \"orange\", \"lightgreen\"]\n",
    "    labels = [\n",
    "        f\"Alpaca \\n  {v['llama_gpt3_win']*100:.2f}%\",\n",
    "        f\"LLaMA-GPT4 \\n {v['llama_gpt4_win']*100:.2f}%\",\n",
    "        f\"Tie \\n {v['Tie']*100:.2f}%\",\n",
    "    ]\n",
    "    axs[i].pie(\n",
    "        v.values(),\n",
    "        labels=labels,\n",
    "        colors=colors,\n",
    "        labeldistance=0.24,\n",
    "        wedgeprops={\"alpha\": 0.7},\n",
    "    )\n",
    "    axs[i].set_title(k, y=-0.01)\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.2)\n",
    "plt.rcParams.update({\"font.size\": 10})\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"output/pie_llama_gpt3_vs_llam_gpt4.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GPT4 Evaluation\n",
    "\n",
    "The 80 questions from Vicuna is used (https://github.com/lm-sys/FastChat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * All chatbots are compared against gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m lst \u001b[39min\u001b[39;00m score_list:\n\u001b[0;32m     18\u001b[0m     ratios\u001b[39m.\u001b[39mappend(lst[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m lst[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100.0\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m2.0\u001b[39m))\n\u001b[0;32m     21\u001b[0m ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca() \n\u001b[0;32m     22\u001b[0m ax\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mgrid(\u001b[39mTrue\u001b[39;00m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "review_gpt35_gpt4 = [652.0, 714.0]\n",
    "review_gpt4_gpt35 = [613.0, 521.0]\n",
    "review_llama_gpt4_gpt4 = [606.0, 726.5]\n",
    "review_llama_gpt4_gpt4_r1 = [631.0, 722.5]\n",
    "review_llama_gpt4 = [520.0, 731.5]\n",
    "review_alpaca_gpt4 = [593.0, 745.5]\n",
    "review_vicuna_gpt4 = [640.0, 715.5]\n",
    "review_bard_gpt4 = [633.0, 722.0]\n",
    "review_gpt4_gpt4 = [760.0, 760.0]\n",
    "\n",
    "\n",
    "name_list = [\n",
    "    \"LLaMA (13B)\",\n",
    "    \"Alpaca (13B)\",\n",
    "    \"Vicuna (13B)\",\n",
    "    \"LLaMA_GPT4 (7B)\",\n",
    "    \"LLaMA_GPT4 (7B, R1)\",\n",
    "    \"Bard\",\n",
    "    \"ChatGPT\",\n",
    "    \"GPT4\",\n",
    "]\n",
    "score_list = [\n",
    "    review_llama_gpt4,\n",
    "    review_alpaca_gpt4,\n",
    "    review_vicuna_gpt4,\n",
    "    review_llama_gpt4_gpt4,\n",
    "    review_llama_gpt4_gpt4_r1,\n",
    "    review_bard_gpt4,\n",
    "    review_gpt35_gpt4,\n",
    "    review_gpt4_gpt4,\n",
    "]\n",
    "color_list = [\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"orange\",\n",
    "    \"orange\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"skyblue\",\n",
    "]\n",
    "\n",
    "ratios = []\n",
    "for lst in score_list:\n",
    "    ratios.append(lst[0] / lst[1] * 100.0)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 2.0))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.barh(name_list, ratios, color=color_list)\n",
    "\n",
    "for index, value in enumerate(ratios):\n",
    "    plt.text(value + 1, index - 0.2, \"{:.0f}%\".format(value))\n",
    "    plt.text(\n",
    "        value - 8,\n",
    "        index - 0.2,\n",
    "        f\"{score_list[index][0]:.0f} : {score_list[index][1]:.0f}\",\n",
    "    )\n",
    "\n",
    "plt.xlim(60, 105)\n",
    "# Left Y-axis labels\n",
    "plt.xticks(\n",
    "    (60, 70, 80, 90, 100), (\"60%\", \"70%\", \"80%\", \"90%\", \"100%\"), color=\"k\", size=10\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"output/bar_score_all_vs_gpt4.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * All chatbots are compared against ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m lst \u001b[39min\u001b[39;00m score_list:\n\u001b[0;32m     18\u001b[0m     ratios\u001b[39m.\u001b[39mappend(lst[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m lst[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100.0\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m2.0\u001b[39m))\n\u001b[0;32m     21\u001b[0m ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca() \n\u001b[0;32m     22\u001b[0m ax\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mgrid(\u001b[39mTrue\u001b[39;00m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "review_gpt35_gpt35 = [759.0, 759.0]\n",
    "review_llama_gpt4_gpt35 = [609.0, 666.5]  # [609.0, 669.0]\n",
    "review_llama_gpt4_gpt35_r1 = [624.0, 667.0]  # [601.0, 674.0]\n",
    "review_llama_gpt35 = [502.0, 698.5]\n",
    "review_alpaca_gpt35 = [585.0, 704.5]\n",
    "review_vicuna_gpt35 = [649.0, 652.5]\n",
    "review_bard_gpt35 = [634.0, 660.0]\n",
    "review_gpt4_gpt35 = [613.0, 521.0]\n",
    "\n",
    "\n",
    "name_list = [\n",
    "    \"LLaMA (13B)\",\n",
    "    \"Alpaca (13B)\",\n",
    "    \"Vicuna (13B)\",\n",
    "    \"LLaMA_GPT4 (7B)\",\n",
    "    \"LLaMA_GPT4 (7B, R1)\",\n",
    "    \"Bard\",\n",
    "    \"ChatGPT\",\n",
    "    \"GPT4\",\n",
    "]  # 'LLaMA_GPT4 (13B)'\n",
    "score_list = [\n",
    "    review_llama_gpt35,\n",
    "    review_alpaca_gpt35,\n",
    "    review_vicuna_gpt35,\n",
    "    review_llama_gpt4_gpt35,\n",
    "    review_llama_gpt4_gpt35_r1,\n",
    "    review_bard_gpt35,\n",
    "    review_gpt35_gpt35,\n",
    "    review_gpt4_gpt35,\n",
    "]\n",
    "color_list = [\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"orange\",\n",
    "    \"orange\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"skyblue\",\n",
    "]\n",
    "\n",
    "ratios = []\n",
    "for lst in score_list:\n",
    "    ratios.append(lst[0] / lst[1] * 100.0)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 2.0))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.barh(name_list, ratios, color=color_list)\n",
    "\n",
    "for index, value in enumerate(ratios):\n",
    "    plt.text(value + 1, index - 0.1, \"{:.0f}%\".format(value))\n",
    "    plt.text(\n",
    "        value - 10,\n",
    "        index - 0.1,\n",
    "        f\"{score_list[index][0]:.0f} : {score_list[index][1]:.0f}\",\n",
    "    )\n",
    "\n",
    "plt.xlim(60, 125)\n",
    "# Left Y-axis labels\n",
    "plt.xticks(\n",
    "    (60, 70, 80, 90, 100), (\"60%\", \"70%\", \"80%\", \"90%\", \"100%\"), color=\"k\", size=10\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"output/bar_score_all_vs_gpt35.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * The effectivness of the reward model: each ranked group is comapared against GPT and ChatGPT, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 50\u001b[0m\n\u001b[0;32m     46\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     48\u001b[0m     fig\u001b[39m.\u001b[39msavefig(file_name, bbox_inches\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m plot_bar(llama_gpt4_ranks_gpt35, name_list, \u001b[39m'\u001b[39;49m\u001b[39moutput/bar_score_ranking_vs_gpt35.pdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     51\u001b[0m plot_bar(llama_gpt4_ranks_gpt4, name_list,  \u001b[39m'\u001b[39m\u001b[39moutput/bar_score_ranking_vs_gpt4.pdf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 31\u001b[0m, in \u001b[0;36mplot_bar\u001b[1;34m(score_list, name_list, file_name)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m lst \u001b[39min\u001b[39;00m score_list:\n\u001b[0;32m     29\u001b[0m     ratios\u001b[39m.\u001b[39mappend(lst[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m lst[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100.0\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m2.8\u001b[39m,\u001b[39m1.7\u001b[39m))\n\u001b[0;32m     32\u001b[0m ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca() \n\u001b[0;32m     33\u001b[0m ax\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mgrid(\u001b[39mTrue\u001b[39;00m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "llama_gpt4_rank0_gpt35 = [624.0, 667.0]\n",
    "llama_gpt4_rank0_gpt4 = [631.0, 722.5]\n",
    "llama_gpt4_rank1_gpt35 = [614.0, 670.0]\n",
    "llama_gpt4_rank1_gpt4 = [614.0, 720.5]\n",
    "llama_gpt4_rank2_gpt35 = [623.0, 681.5]\n",
    "llama_gpt4_rank2_gpt4 = [615.0, 724.0]\n",
    "llama_gpt4_rank3_gpt35 = [597.0, 669.0]\n",
    "llama_gpt4_rank3_gpt4 = [602.0, 726.0]\n",
    "llama_gpt4_rank4_gpt35 = [605.0, 677.5]\n",
    "llama_gpt4_rank4_gpt4 = [605.0, 726.0]\n",
    "\n",
    "\n",
    "review_llama_gpt4_gpt4 = [606.0, 726.5]\n",
    "review_llama_gpt4_gpt35 = [609.0, 666.5]\n",
    "\n",
    "\n",
    "llama_gpt4_ranks_gpt35 = [\n",
    "    [624.0, 667.0],\n",
    "    [614.0, 670.0],\n",
    "    [623.0, 681.5],\n",
    "    [597.0, 669.0],\n",
    "    [605.0, 677.5],\n",
    "] + [review_llama_gpt4_gpt35]\n",
    "llama_gpt4_ranks_gpt4 = [\n",
    "    [631.0, 722.5],\n",
    "    [614.0, 720.5],\n",
    "    [615.0, 724.0],\n",
    "    [602.0, 726.0],\n",
    "    [605.0, 726.0],\n",
    "] + [review_llama_gpt4_gpt4]\n",
    "name_list = [str(i + 1) for i in range(5)]\n",
    "\n",
    "name_list += [\"B\"]\n",
    "color_list = [\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"orange\",\n",
    "]\n",
    "\n",
    "\n",
    "def plot_bar(score_list, name_list, file_name):\n",
    "    ratios = []\n",
    "    for lst in score_list:\n",
    "        ratios.append(lst[0] / lst[1] * 100.0)\n",
    "\n",
    "    fig = plt.figure(figsize=(2.8, 1.7))\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "    plt.barh(name_list, ratios, color=color_list)\n",
    "\n",
    "    for index, value in enumerate(ratios):\n",
    "        plt.text(value + 1, index - 0.1, \"{:.0f}%\".format(value))\n",
    "        plt.text(\n",
    "            value - 15,\n",
    "            index - 0.1,\n",
    "            f\"{score_list[index][0]:.0f} : {score_list[index][1]:.0f}\",\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"Ranking Group\", fontsize=10)\n",
    "\n",
    "    plt.xlim(60, 101)\n",
    "    # Left Y-axis labels\n",
    "    plt.xticks(\n",
    "        (60, 70, 80, 90, 100), (\"60%\", \"70%\", \"80%\", \"90%\", \"100%\"), color=\"k\", size=10\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(file_name, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "plot_bar(llama_gpt4_ranks_gpt35, name_list, \"output/bar_score_ranking_vs_gpt35.pdf\")\n",
    "plot_bar(llama_gpt4_ranks_gpt4, name_list, \"output/bar_score_ranking_vs_gpt4.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Chinese Instruction-Following Performance\n",
    "\n",
    "#### All chatbots (answers are translated from English to Chiense) are compared with GPT4\n",
    "\n",
    "- *gpt_4_t: translated Chinese answers\n",
    "- *gpt_4_g: generated Chinese anwsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     44\u001b[0m     fig\u001b[39m.\u001b[39msavefig(file_name, bbox_inches\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m plot_bar(score_list_g, name_list, (\u001b[39m58\u001b[39;49m, \u001b[39m115\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39moutput/bar_score_all_vs_gpt4_g_cn.pdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     47\u001b[0m plot_bar(score_list_t, name_list, (\u001b[39m58\u001b[39m, \u001b[39m115\u001b[39m), \u001b[39m'\u001b[39m\u001b[39moutput/bar_score_all_vs_gpt4_t_cn.pdf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 29\u001b[0m, in \u001b[0;36mplot_bar\u001b[1;34m(score_list, name_list, xlim, file_name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m lst \u001b[39min\u001b[39;00m score_list:\n\u001b[0;32m     27\u001b[0m     ratios\u001b[39m.\u001b[39mappend(lst[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m lst[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100.0\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m2.0\u001b[39m))\n\u001b[0;32m     30\u001b[0m ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca() \n\u001b[0;32m     31\u001b[0m ax\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mgrid(\u001b[39mTrue\u001b[39;00m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "llama_13b_t_gpt4_g_cn = [500.0, 699.0]\n",
    "llama_13b_t_gpt4_t_cn = [466.0, 697.0]\n",
    "vicuna_13b_t_gpt4_g_cn = [658.0, 677.0]\n",
    "vicuna_13b_t_gpt4_t_cn = [639.0, 687.5]\n",
    "alpaca_13b_t_gpt4_g_cn = [551.0, 702.0]\n",
    "alpaca_13b_t_gpt4_t_cn = [539.0, 712.0]\n",
    "bard_t_gpt4_g_cn = [642.0, 678.0]\n",
    "bard_t_gpt4_t_cn = [624.0, 681.0]\n",
    "gpt35_t_gpt4_g_cn = [658.0, 679.0]\n",
    "gpt35_t_gpt4_t_cn = [652.5, 684.5]\n",
    "gpt4_t_gpt4_g_cn = [680.5, 626.5]\n",
    "gpt4_t_gpt4_t_cn = [758.0, 758.0]\n",
    "llama_gpt4_t_gpt4_g_cn = [618.5, 685.5]\n",
    "llama_gpt4_t_gpt4_t_cn = [607.0, 700.0]\n",
    "llama_gpt4_rank0_t_gpt4_g_cn = [629.0, 672.0]\n",
    "llama_gpt4_rank0_t_gpt4_t_cn = [620.0, 693.0]\n",
    "\n",
    "name_list = [\n",
    "    \"LLaMA (13B)\",\n",
    "    \"Alpaca (13B)\",\n",
    "    \"Vicuna (13B)\",\n",
    "    \"LLaMA_GPT4 (7B)\",\n",
    "    \"LLaMA_GPT4 (7B, R1)\",\n",
    "    \"Bard\",\n",
    "    \"ChatGPT\",\n",
    "    \"GPT4\",\n",
    "]  # 'LLaMA_GPT4 (13B)'\n",
    "score_list_g = [\n",
    "    llama_13b_t_gpt4_g_cn,\n",
    "    alpaca_13b_t_gpt4_g_cn,\n",
    "    vicuna_13b_t_gpt4_g_cn,\n",
    "    llama_gpt4_t_gpt4_g_cn,\n",
    "    llama_gpt4_rank0_t_gpt4_g_cn,\n",
    "    bard_t_gpt4_g_cn,\n",
    "    gpt35_t_gpt4_g_cn,\n",
    "    gpt4_t_gpt4_g_cn,\n",
    "]\n",
    "score_list_t = [\n",
    "    llama_13b_t_gpt4_t_cn,\n",
    "    alpaca_13b_t_gpt4_t_cn,\n",
    "    vicuna_13b_t_gpt4_t_cn,\n",
    "    llama_gpt4_t_gpt4_t_cn,\n",
    "    llama_gpt4_rank0_t_gpt4_t_cn,\n",
    "    bard_t_gpt4_t_cn,\n",
    "    gpt35_t_gpt4_t_cn,\n",
    "    gpt4_t_gpt4_t_cn,\n",
    "]\n",
    "color_list = [\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"orange\",\n",
    "    \"orange\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"skyblue\",\n",
    "]\n",
    "\n",
    "\n",
    "def plot_bar(score_list, name_list, xlim, file_name):\n",
    "    ratios = []\n",
    "    for lst in score_list:\n",
    "        ratios.append(lst[0] / lst[1] * 100.0)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 2.0))\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "    plt.barh(name_list, ratios, color=color_list)\n",
    "\n",
    "    for index, value in enumerate(ratios):\n",
    "        plt.text(value + 1, index - 0.2, \"{:.0f}%\".format(value))\n",
    "        plt.text(\n",
    "            value - 8,\n",
    "            index - 0.2,\n",
    "            f\"{score_list[index][0]:.0f} : {score_list[index][1]:.0f}\",\n",
    "        )\n",
    "\n",
    "    plt.xlim(xlim[0], xlim[1])\n",
    "    # Left Y-axis labels\n",
    "    plt.xticks(\n",
    "        (60, 70, 80, 90, 100), (\"60%\", \"70%\", \"80%\", \"90%\", \"100%\"), color=\"k\", size=10\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(file_name, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "plot_bar(score_list_g, name_list, (58, 115), \"output/bar_score_all_vs_gpt4_g_cn.pdf\")\n",
    "plot_bar(score_list_t, name_list, (58, 115), \"output/bar_score_all_vs_gpt4_t_cn.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * All chatbots are compared with GPT4 (Both the instruction and answers are Chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     40\u001b[0m     fig\u001b[39m.\u001b[39msavefig(file_name, bbox_inches\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m plot_bar(score_list, name_list, (\u001b[39m20\u001b[39;49m, \u001b[39m100\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39moutput/bar_score_all_gen_cn_vs_gpt4_t_cn.pdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[17], line 25\u001b[0m, in \u001b[0;36mplot_bar\u001b[1;34m(score_list, name_list, xlim, file_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m lst \u001b[39min\u001b[39;00m score_list:\n\u001b[0;32m     23\u001b[0m     ratios\u001b[39m.\u001b[39mappend(lst[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m lst[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100.0\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m1.3\u001b[39m))\n\u001b[0;32m     26\u001b[0m ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca() \n\u001b[0;32m     27\u001b[0m ax\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mgrid(\u001b[39mTrue\u001b[39;00m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "llama_to_question_t_gpt4_t_cn = [233.0, 707.0]\n",
    "alpaca_to_question_t_gpt4_t_cn = [259.0, 724.0]\n",
    "llama_gpt4_to_question_t_gpt4_t_cn = [253.0, 723.0]\n",
    "llama_gpt4_cn_to_question_t_gpt4_t_cn = [356.0, 683.0]\n",
    "llama_gpt4_cn_to_question_v2_t_gpt4_t_cn = [445.0, 694.0]\n",
    "\n",
    "\n",
    "llama_gpt4_cn_to_question_v2_t_gpt4_g_cn = [463.0, 693.0]\n",
    "gpt4_g_gpt4_t_cn = [626.5, 680.5]\n",
    "\n",
    "vicuna_13b_to_question_v1_t_gpt4_g_cn = [545.0, 691.0]\n",
    "vicuna_13b_to_question_v1_t_gpt4_t_cn = [526.5, 702.0]\n",
    "\n",
    "\n",
    "name_list = [\n",
    "    \"LLaMA (13B)\",\n",
    "    \"Alpaca (13B)\",\n",
    "    \"Vicuna (13B)\",\n",
    "    \"LLaMA_GPT4 (7B)\",\n",
    "    \"LLaMA_GPT4_CN (7B)\",\n",
    "    \"GPT4\",\n",
    "]  # 'LLaMA_GPT4 (13B)'\n",
    "score_list = [\n",
    "    llama_to_question_t_gpt4_t_cn,\n",
    "    alpaca_to_question_t_gpt4_t_cn,\n",
    "    vicuna_13b_to_question_v1_t_gpt4_g_cn,\n",
    "    llama_gpt4_to_question_t_gpt4_t_cn,\n",
    "    llama_gpt4_cn_to_question_v2_t_gpt4_t_cn,\n",
    "    gpt4_g_gpt4_t_cn,\n",
    "]\n",
    "color_list = [\"lightgreen\", \"lightgreen\", \"lightgreen\", \"orange\", \"orange\", \"skyblue\"]\n",
    "\n",
    "\n",
    "def plot_bar(score_list, name_list, xlim, file_name):\n",
    "    ratios = []\n",
    "    for lst in score_list:\n",
    "        ratios.append(lst[0] / lst[1] * 100.0)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 1.3))\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "    plt.barh(name_list, ratios, color=color_list)\n",
    "\n",
    "    for index, value in enumerate(ratios):\n",
    "        plt.text(value + 1, index - 0.2, \"{:.0f}%\".format(value))\n",
    "        plt.text(\n",
    "            value - 12,\n",
    "            index - 0.2,\n",
    "            f\"{score_list[index][0]:.0f} : {score_list[index][1]:.0f}\",\n",
    "        )\n",
    "\n",
    "    plt.xlim(xlim[0], xlim[1])\n",
    "    # Left Y-axis labels\n",
    "    plt.xticks(\n",
    "        (20, 40, 60, 80, 100), (\"20%\", \"40%\", \"60%\", \"80%\", \"100%\"), color=\"k\", size=10\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(file_name, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "plot_bar(\n",
    "    score_list, name_list, (20, 100), \"output/bar_score_all_gen_cn_vs_gpt4_t_cn.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unnatural Instruction Breakdown Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/eval_unnatural_instructions/gpt4_unnatural_instruction_results_h9000_len0-2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m res_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m len_req:\n\u001b[1;32m----> 7\u001b[0m     f_data \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexpanduser(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/eval_unnatural_instructions/gpt4_unnatural_instruction_results_h9000_len\u001b[39;49m\u001b[39m{\u001b[39;49;00ml\u001b[39m}\u001b[39;49;00m\u001b[39m.json\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f_data)\n\u001b[0;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/eval_unnatural_instructions/gpt4_unnatural_instruction_results_h9000_len0-2.json'"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "len_req = [\"0-2\", \"3-5\", \"6-10\", \"10-\", \"ALL\"]\n",
    "\n",
    "res_dict = {}\n",
    "for l in len_req:\n",
    "    f_data = open(\n",
    "        os.path.expanduser(\n",
    "            f\"data/eval_unnatural_instructions/gpt4_unnatural_instruction_results_h9000_len{l}.json\"\n",
    "        ),\n",
    "        \"r\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    data = json.load(f_data)\n",
    "\n",
    "    for d in data:\n",
    "        if d[\"Model\"] not in res_dict:\n",
    "            res_dict[d[\"Model\"]] = [d[\"rougeL\"]]\n",
    "        else:\n",
    "            res_dict[d[\"Model\"]].append(d[\"rougeL\"])\n",
    "\n",
    "\n",
    "print(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m2.5\u001b[39m))\n\u001b[0;32m      3\u001b[0m bars \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m0-2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m3-5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m6-10\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m10>\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m x_pos \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(bars))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 2.5))\n",
    "\n",
    "bars = [\"0-2\", \"3-5\", \"6-10\", \"10>\"]\n",
    "x_pos = np.arange(len(bars))\n",
    "\n",
    "\n",
    "means = {k: v[-1] for k, v in res_dict.items()}\n",
    "\n",
    "means_Alpaca = means[\"Alpaca\"]\n",
    "means_Alpaca_GPT4 = means[\"Alpaca-GPT4\"]\n",
    "means_GPT4 = means[\"GPT4\"]\n",
    "\n",
    "bar_plot1 = plt.bar(\n",
    "    x_pos - 0.2,\n",
    "    res_dict[\"Alpaca\"][:-1],\n",
    "    color=[\"lightgreen\"],\n",
    "    width=0.2,\n",
    "    label=f\"Alpaca: {means_Alpaca:.2f}\",\n",
    ")\n",
    "bar_plot2 = plt.bar(\n",
    "    x_pos,\n",
    "    res_dict[\"Alpaca-GPT4\"][:-1],\n",
    "    color=[\"orange\"],\n",
    "    width=0.2,\n",
    "    label=f\"LLaMA-GPT4: {means_Alpaca_GPT4:.2f}\",\n",
    ")\n",
    "plt.bar(\n",
    "    x_pos + 0.2,\n",
    "    res_dict[\"GPT4\"][:-1],\n",
    "    color=[\"skyblue\"],\n",
    "    width=0.2,\n",
    "    label=f\"GPT4: {means_GPT4:.2f}\",\n",
    ")\n",
    "\n",
    "bar_label = [res_dict[\"Alpaca-GPT4\"][i] - res_dict[\"GPT4\"][i] for i in range(len(bars))]\n",
    "bar_label_color = [1 if b > 0 else 0 for b in bar_label]\n",
    "bar_label = [\"+\" + str(b)[:6] if b > 0 else \"-\" + str(b)[1:6] for b in bar_label]\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    for idx, rect in enumerate(bar_plot2):\n",
    "        height = rect.get_height()\n",
    "        plt.text(\n",
    "            rect.get_x() + rect.get_width() / 2.0,\n",
    "            1.02 * height,\n",
    "            bar_label[idx],\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            rotation=0,\n",
    "            size=13,\n",
    "            color=\"green\" if bar_label_color[idx] == 1 else \"red\",\n",
    "        )\n",
    "\n",
    "\n",
    "autolabel(bar_plot2)\n",
    "\n",
    "\n",
    "bar_label = [res_dict[\"Alpaca\"][i] - res_dict[\"GPT4\"][i] for i in range(len(bars))]\n",
    "bar_label_color = [1 if b > 0 else 0 for b in bar_label]\n",
    "bar_label = [\"+\" + str(b)[:6] if b > 0 else \"-\" + str(b)[1:6] for b in bar_label]\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    for idx, rect in enumerate(bar_plot1):\n",
    "        height = rect.get_height()\n",
    "        plt.text(\n",
    "            rect.get_x() + rect.get_width() / 2.0,\n",
    "            1.02 * height,\n",
    "            bar_label[idx],\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            rotation=0,\n",
    "            size=13,\n",
    "            color=\"green\" if bar_label_color[idx] == 1 else \"red\",\n",
    "        )\n",
    "\n",
    "\n",
    "autolabel(bar_plot1)\n",
    "\n",
    "\n",
    "leg = plt.legend(fontsize=12, shadow=True, loc=(0.02, 0.8), ncol=3)\n",
    "plt.xticks(x_pos - 0.15, bars, rotation=0, color=\"k\", size=11)\n",
    "plt.yticks(\n",
    "    (0.0, 0.1, 0.2, 0.3, 0.4, 0.5),\n",
    "    (\"0.0\", \"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\"),\n",
    "    color=\"k\",\n",
    "    size=12,\n",
    ")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Groundtruth Response Length\", fontsize=12)\n",
    "plt.ylabel(\"RougeL\", fontsize=12)\n",
    "\n",
    "\n",
    "plt.xlim(-0.5, len(bars) - 0.5)\n",
    "plt.ylim(0.28, 0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig(\"output/bar_unnatural.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-instruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "364c1b690e879c5ffe4e7bee613e5b5479420b51b03f29835176bef56dfadb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
